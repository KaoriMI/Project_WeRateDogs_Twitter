****
# twitter authentication 
import tweepy

consumer_key = 'TT2D0E2aIX0VEMNDs1ZdRll7W'
consumer_secret = '7Qv623gWuw4H8gvIWtHJ4ZB8gw6kz6cRdllGP8bzYIAKxYTDHU'
access_token = '1322275579496927233-6yA5Xz158culvlLTkTJND36bdSIsJR'
access_secret = 'fHqvXqAhZVMGovtvXF6AoSK2tuoDul5bIrNCoYDADjrkJ'
******



# Code : 2
dog_stage = ['doggo','floofer', 'pupper', 'puppo']

for stage in dog_stage:
    df_clean[stage] = df_clean[stage].str.contains(stage).astype(int)
    
    
# test : 2 
for stage in dog_stage:
    print((df_clean[stage] == (df_tw[(pd.isnull(df_tw['in_reply_to_status_id'])) & (pd.isnull(df_tw['retweeted_status_id']))].reset_index(drop=True)[stage] == stage)).unique())
    
    
    
    
<Data>
-Enhanced twitter archive
-Additional data via the twitter API (retweet count, favorite count)
-Image predictions file


<suspecious>
-name
-stage
-rating
-dont count retweets

<to do>
-Data wrangling(wrangle_act.ipynb)
    Gathering data(tweet_json.txt for downloading tweet)
    Assessing data(8 quality issues and 2 tidiness issues (tidiness -merging data is included))
    Cleaning data 
-Storing(save csv as twitter_archive_master.csv)
-analyzing, and visualizing (inside of wrangle_act.ipynb, 3insights and 1 visualization)
-Reporting on 1) your data wrangling efforts and 2) your data analyses and visualizations
  ->300-600, called wrangle_report.pdf or wrangle_report.html that briefly describes your wrangling efforts. This is to be framed as an internal document.
  ->250-word-minimum written report called act_report.pdf or act_report.html that communicates the insights and displays the visualization(s) produced from your wrangled data. This is to be framed as an external document, like a blog post or magazine article, for example.




Your goal
wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. 

Wrangling
The ratings probably aren't all correct. Same goes for the dog names and probably dog stages (see below for more information on these) too. 

Twitter API
Retweet count 
favorite count

image predictions file
tweet_id is the last part of the tweet URL after "status/" → https://twitter.com/dog_rates/status/889531135344209921
p1 is the algorithm's #1 prediction for the image in the tweet → golden retriever
p1_conf is how confident the algorithm is in its #1 prediction → 95%
p1_dog is whether or not the #1 prediction is a breed of dog → TRUE
p2 is the algorithm's second most likely prediction → Labrador retriever
p2_conf is how confident the algorithm is in its #2 prediction → 1%
p2_dog is whether or not the #2 prediction is a breed of dog → TRUE

Key Points
Key points to keep in mind when data wrangling for this project:

-You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.

-Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.

-Cleaning includes merging individual pieces of data according to the rules of tidy data.
-The fact that the rating numerators are greater than the denominators does not need to be cleaned. This unique rating system is a big part of the popularity of WeRateDogs.
-You do not need to gather the tweets beyond August 1st, 2017. You can, but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used.

quality

******


done>Dtype:
 - timestamp is not time series data.
 - each dog stage is not boolean.
 - ID related column is either int64 or float 64. This should be string.


done>remove- retweet/reply and include the table
denomitor > 10
denomitor == 0

include floof in floofer

dog_name = 1, 0 , this, lower case etc..

image prediction= delete 
image prediction id to object
tweet


*******

in

tidiness
-tweet_id: int -> obj
-these: float -> obj
 1   in_reply_to_status_id       78 non-null     float64
 2   in_reply_to_user_id         78 non-null     float64
 6   retweeted_status_id         181 non-null    float64
 7   retweeted_status_user_id    181 non-null    float64
 -time stamp
 object -> time

 -
*********
#### Quality issues 
##### ◆Twitter archive data
&nbsp;-Data type to be changed: <br>
>&nbsp;Timestamp (->time series data)<br>
&nbsp;Dog stage (-> Boolean)<br>
&nbsp;ID's (-> string/object)<br>

&nbsp;-Some denominators are incorrect.<br>
&nbsp;-"Floof" is not included in floofer stage.<br>
&nbsp;-Some dog names are incorrect.<br> 
##### ◆Image prediction
&nbsp;-Some predisctions are not a dog.<br>
&nbsp;-Tweet ID is not string/object.<br>
&nbsp;-Some data are missing.<br>
<br>
#### Tidiness issues
##### ◆Twitter archive data
&nbsp;-Text column includes URL of the tweets.<br>
&nbsp;-Retweets / replies are included.<br>
&nbsp;-The number of retweet / reply is in a separate dataframe.<br>
**
define
code
test